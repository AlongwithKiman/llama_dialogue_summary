{
  "peft_config": { "r": 8, "lora_alpha": 32, "lora_dropout": 0.05 },
  "train_config": {
    "learning_rate": 1e-4,
    "num_train_epochs": 1,
    "gradient_accumulation_steps": 2,
    "per_device_train_batch_size": 2,
    "gradient_checkpointing": false,
    "output_dir": "/dataset/0607_llama3_4bit",
    "model_ckpt_save_dir": "/dataset/model/kollama3_0607_4bit"
  },
  "dataset_config": {
    "dataset_path": "/dataset/concat_processed.json",
    "chunk_size": 1024
  },
  "model_config": {
    "model_id": "beomi/Llama-3-Open-Ko-8B",
    "load_in_bit": 4,
    "cache_dir": "/dataset/huggingface_cache",
    "token": "YOUR_HF_TOKEN_HERE"
  }
}
